{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de NBV \n",
    "\n",
    "En este notebook implementaremos un sistema para reconstrucción via NBV haciendo uso de la arquitectura autoencoder y MLP\n",
    "\n",
    "* pedirá la dirección a la carpeta contenedora del objeto\n",
    "* Creará un link simbolico para acceder a las texturas (verifica si no existe ya) y carpetas para almacenar la información obtenida durante el proceso: \n",
    "    - Nubes de puntos\n",
    "    - RGB\n",
    "    - Profundidad\n",
    "* Despliega el objeto para verificar si es el que espera el usuario y debe confirmar si es correcto\n",
    "* Genera una posición y orientación random (podría extraerla de Hintertoiser), importante conocer el bounding box para no colisionar con el objeto\n",
    "* Inicia el proceso de reconstrucción\n",
    "* Captura información y almacena \n",
    "* Crea grid de 31x31x31\n",
    "* Procesamiento de IA\n",
    "* Condición si la cumple repite o finaliza\n",
    "* Reporte de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from symlink import symbolic_dir\n",
    "import open3d as o3d\n",
    "import octomap\n",
    "import torch\n",
    "from utils_o3d import Get_Pointcloud, Get_RGBD, Get_octree\n",
    "from MLP import MLP\n",
    "from utils import net_sample_output_nbv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingresa la dirección a la carpeta contenedora del banco de datos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Inicia el proceso de reconstrucción ...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/position/weights_entrenamiento_MLP_11.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m model\u001b[38;5;241m=\u001b[39m MLP()\u001b[38;5;241m.\u001b[39mcuda() \n\u001b[1;32m     38\u001b[0m path_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/position/weights_entrenamiento_MLP_11.pth\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m## Modificar direccion de pesos\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_weights\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     40\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mcurrent_device()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#Inicializamos el octomap\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/o3d/lib/python3.11/site-packages/torch/serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/o3d/lib/python3.11/site-packages/torch/serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/envs/o3d/lib/python3.11/site-packages/torch/serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/position/weights_entrenamiento_MLP_11.pth'"
     ]
    }
   ],
   "source": [
    "print(\"Ingresa la dirección a la carpeta contenedora del banco de datos\")\n",
    "direccion = input(\"Cúal es la dirección a la carpeta contenedora?:\") # Dataset acces\n",
    "print(list(filter(os.path.isdir, os.listdir(direccion))))\n",
    "carpeta = input(\"A que carpeta quieres acceder?: \") #object folder\n",
    "dir_carpeta = direccion + carpeta\n",
    "if os.path.lexists(dir_carpeta + \"/meshes/texture.png\") == False:\n",
    "    symbolic_dir(dir_carpeta)\n",
    "    RGB = \"/RGB\"\n",
    "    Depth = \"/Depth\"\n",
    "    Point_cloud = \"/Point_cloud\"\n",
    "    os.mkdir(dir_carpeta + RGB)\n",
    "    os.mkdir(dir_carpeta + Depth)\n",
    "    os.mkdir(dir_carpeta + Point_cloud)\n",
    "    #print(\"Cree link simbolico\")\n",
    "visualizar = input(\"Quieres visualizar el objeto? (presiona S en caso de sí):\") \n",
    "if visualizar == 'S'  or  visualizar == 's' :\n",
    "    mesh = o3d.io.read_triangle_mesh(dir_carpeta + '/meshes/model.obj', True) \n",
    "    o3d.visualization.draw_geometries([mesh])\n",
    "\n",
    "global p_c\n",
    "\n",
    "fov = 17.7064\n",
    "img_H = 100\n",
    "img_W = 100\n",
    "up = [0, 1, 0]\n",
    "cent = [0.5,0.5,0.5]\n",
    "eye = [2.0,1.0,2.0]\n",
    "resolution = 0.01\n",
    "\n",
    "## TODO: Aqui generamos la vista random\n",
    "\n",
    "print(\"Inicia el proceso de reconstrucción ...\")\n",
    "\n",
    "condicion = False\n",
    "i = 0\n",
    "#Cargamos los modelos de predicción de posición\n",
    "model= MLP().cuda() \n",
    "path_weights = '/position/weights_entrenamiento_MLP_11.pth' ## Modificar direccion de pesos\n",
    "model.load_state_dict(torch.load(path_weights))\n",
    "device = torch.cuda.current_device()\n",
    "\n",
    "#Inicializamos el octomap\n",
    "resolution = 0.01 # resolucion del octree\n",
    "octree = octomap.OcTree(resolution) # inicializamos el octree\n",
    "\n",
    "while condicion == False:\n",
    "    #Cargamos malla\n",
    "    mesh = o3d.io.read_triangle_mesh('objetos/' + 'meshes/model.obj', True)\n",
    "\n",
    "    # Raycasting\n",
    "    mesh1 = o3d.t.geometry.TriangleMesh.from_legacy(mesh)\n",
    "    scene = o3d.t.geometry.RaycastingScene()\n",
    "    scene.add_triangles(mesh1)\n",
    "    # render for RGBD images\n",
    "    \n",
    "    render = o3d.visualization.rendering.OffscreenRenderer(width=img_W, height=img_H) #Linux only\n",
    "    render.scene.add_geometry('mesh', mesh)\n",
    "\n",
    "    # RGBD and pointcloud extraction\n",
    "    Get_Pointcloud(scene, fov, cent, eye, up, img_W, img_H, dir_carpeta, i)\n",
    "    Get_RGBD(render,  fov, cent, eye, up, dir_carpeta, i)\n",
    "    #Occupancy grid\n",
    "    octree =  Get_octree(pc, i)\n",
    "    torch_grid = torch.from_numpy(grid)\n",
    "    \n",
    "    #IA\n",
    "    #output, _= net_sample_output_nbv(model, grid, device) \n",
    "    \n",
    "    #Evaluacion\n",
    "    # Esta completa la reconstrucción?\n",
    "    # si condicion = False\n",
    "    # continua\n",
    "    # si condicion = True \n",
    "    # break \n",
    "    # Metricas \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: verificar que pasa con la geometria, si es necesario mejor leer la nube de puntos para no tener inconvenientes\n",
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02635956, 0.02606279, 0.08874011])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pc.get_max_bound()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/Saulo/ProyectoPHD/MODELDATASET/'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import imgviz\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import trimesh.viewer\n",
    "\n",
    "import octomap\n",
    "import sys\n",
    "sys.path.insert(0, '/home/skunkllr/octomappython/examples/')\n",
    "from insertPointCloud import pointcloud_from_depth\n",
    "from insertPointCloud import visualize\n",
    "\n",
    "\n",
    "data = imgviz.data.arc2017() # Carga dataset\n",
    "camera_info = data[\"camera_info\"]\n",
    "K = np.array(camera_info[\"K\"]).reshape(3, 3)\n",
    "rgb = data[\"rgb\"] #selecciona el dataset a utilizar\n",
    "pcd = pointcloud_from_depth(\n",
    "    data[\"depth\"], fx=K[0, 0], fy=K[1, 1], cx=K[0, 2], cy=K[1, 2]\n",
    ") # Se infiere la profundidad a partir de una imagen RGB\n",
    "\n",
    "nonnan = ~np.isnan(pcd).any(axis=2) #filtro para valores nan\n",
    "mask = np.less(pcd[:, :, 2], 2) #mascara    ##### ver que es lo que hace\n",
    "\n",
    "resolution = 0.01 # resolucion del octree\n",
    "octree = octomap.OcTree(resolution) # inicializamos el octree\n",
    "octree.insertPointCloud(\n",
    "    pointcloud=pcd[nonnan],\n",
    "    origin=np.array([0, 0, 0], dtype=float),\n",
    "    maxrange=1.25,\n",
    ") # se agrega el pointcloud y el origen del sensor\n",
    "\n",
    "# Se extrae el minimo y maximo de BBox\n",
    "aabb_min = octree.getMetricMin() \n",
    "aabb_max = octree.getMetricMax()\n",
    "center = (aabb_min + aabb_max) / 2\n",
    "dimension = np.array([31, 31, 31]) # dimension de la voxelizacion\n",
    "origin = center - dimension / 2 * resolution\n",
    "\n",
    "#nuevos BBox  con la nueva resolución\n",
    "aabb_min = origin - resolution / 2\n",
    "aabb_max = origin + dimension * resolution + resolution / 2\n",
    "\n",
    "grid = np.full(dimension, -1, np.int32)\n",
    "transform = trimesh.transformations.scale_and_translate(\n",
    "    scale=resolution, translate=origin\n",
    ") #transformacion\n",
    "points = trimesh.voxel.VoxelGrid(encoding=grid, transform=transform).points # Voxel grid con los puntos de la nube\n",
    "labels = octree.getLabels(points) # extrae las etiquetas o valor ocupacional\n",
    "\n",
    "\n",
    "occupied = points[labels == 1] #Ocupado\n",
    "empty = points[labels == 0] # Vacio\n",
    " # TENEMOS valores en -1 a 1, entonces no se que pasa con el resto de valores (los negativos)\n",
    "visualize(\n",
    "    occupied=occupied,\n",
    "    empty=empty,\n",
    "    K=K,\n",
    "    width=camera_info[\"width\"],\n",
    "    height=camera_info[\"height\"],\n",
    "    rgb=rgb,\n",
    "    pcd=pcd,\n",
    "    mask=mask,\n",
    "    resolution=resolution,\n",
    "    aabb=(aabb_min, aabb_max),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(\n",
    "    occupied=occupied,\n",
    "    empty=empty,\n",
    "    K=K,\n",
    "    width=camera_info[\"width\"],\n",
    "    height=camera_info[\"height\"],\n",
    "    rgb=rgb,\n",
    "    pcd=pcd,\n",
    "    mask=mask,\n",
    "    resolution=resolution,\n",
    "    aabb=(aabb_min, aabb_max),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Try to translate to Open3d\n",
    "\n",
    "#Llegamos con las nubes de puntos en un array con dimensiones [:,:,x3]\n",
    "#impotante retirar punto nan (los vi presentes en una nube de puntos)\n",
    "\n",
    "resolution = 0.01 # resolucion del octree\n",
    "octree = octomap.OcTree(resolution) # inicializamos el octree # inicializar mas arriba\n",
    "octree.insertPointCloud(\n",
    "    pointcloud=pcd[nonnan],                         # Filtrar valores nan\n",
    "    origin=np.array([0, 0, 0], dtype=float),\n",
    "    maxrange=1.25,\n",
    ") # se agrega el pointcloud y el origen del sensor\n",
    "\n",
    "# Se extrae el minimo y maximo de BBox\n",
    "aabb_min = octree.getMetricMin() \n",
    "aabb_max = octree.getMetricMax()\n",
    "center = (aabb_min + aabb_max) / 2\n",
    "dimension = np.array([31, 31, 31]) # dimension de la voxelizacion\n",
    "origin = center - dimension / 2 * resolution\n",
    "\n",
    "#nuevos BBox  con la nueva resolución\n",
    "aabb_min = origin - resolution / 2\n",
    "aabb_max = origin + dimension * resolution + resolution / 2\n",
    "\n",
    "grid = np.full(dimension, -1, np.int32)\n",
    "transform = trimesh.transformations.scale_and_translate(\n",
    "    scale=resolution, translate=origin\n",
    ") #transformacion\n",
    "points = trimesh.voxel.VoxelGrid(encoding=grid, transform=transform).points # Voxel grid con los puntos de la nube\n",
    "\n",
    "labels = octree.getLabels(points) # extrae las etiquetas o valor ocupacional\n",
    "# according to octomap-python # -1: unknown, 0: empty, 1: occupied\n",
    "\n",
    "#according to our dataset # 0.5: unknown, 0: empty, 1: occupied\n",
    "labels = labels.astype(dtype = np.float32)\n",
    "np.place(labels, labels <0, [0.5]) # los valores menores a 0 pasan a ser iguales a 0.5\n",
    "grid = np.reshape(labels,(31,31,31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrackedArray([[-0.17 , -0.2  ,  0.455],\n",
       "              [-0.17 , -0.2  ,  0.465],\n",
       "              [-0.17 , -0.2  ,  0.475],\n",
       "              ...,\n",
       "              [ 0.13 ,  0.1  ,  0.735],\n",
       "              [ 0.13 ,  0.1  ,  0.745],\n",
       "              [ 0.13 ,  0.1  ,  0.755]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "\n",
    "* Parece que el error para extraer el octree esta en octomap/octomap/octomap.pyx \n",
    "    hay que explorarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'octomap.leaf_iterator' object has no attribute '_leaf_iterator__is_end'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moctree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractPointCloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32moctomap/octomap.pyx:505\u001b[0m, in \u001b[0;36moctomap.OcTree.extractPointCloud\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32moctomap/octomap.pyx:257\u001b[0m, in \u001b[0;36m__iter__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'octomap.leaf_iterator' object has no attribute '_leaf_iterator__is_end'"
     ]
    }
   ],
   "source": [
    "octree.extractPointCloud()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "o3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
